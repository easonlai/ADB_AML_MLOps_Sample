{"cells":[{"cell_type":"markdown","source":["Model Training for Diabetes Classification in Azure Databricks with Azure Machine Learning integration."],"metadata":{}},{"cell_type":"code","source":["# Import necessary libraries for model training\nimport requests\nimport pandas as pd\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nimport joblib"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Mount ADLS to read data source.\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n           \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n           \"fs.azure.account.oauth2.client.id\": \"your_application_id\",\n           \"fs.azure.account.oauth2.client.secret\": dbutils.secrets.get(scope=\"your_adb_secret_name\",key=\"your_adb_key_name\"),\n           \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/your_aad_tenant_id/oauth2/token\"}\n\ndbutils.fs.mount(\n  source = \"abfss://your_container_name@your_adls_name.dfs.core.windows.net/\",\n  mount_point = \"/mnt/your_adls_mount_point_name\",\n  extra_configs = configs)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Mount Azure Blob Storage as model artifact store.\ndbutils.fs.mount(\n  source = \"wasbs://your_container_name@your_azure_blob_storage_name.blob.core.windows.net\",\n  mount_point = \"/mnt/your_azure_blob_storage_mount_point_name\",\n  extra_configs = {\"fs.azure.account.key.your_azure_blob_storage_mount_point_name.blob.core.windows.net\":dbutils.secrets.get(scope = \"your_adb_secret_name\", key = \"your_adb_key_name\")})"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Unmount ADLS as needed.\n# dbutils.fs.unmount(\"/mnt/your_adls_mount_point_name\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Unmount Azure Blob Storage as needed.\n# dbutils.fs.unmount(\"/mnt/your_azure_blob_storage_mount_point_name\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# List file in ADLS.\ndbutils.fs.ls(\"/mnt/your_adls_mount_point_name/\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# List file in Azure Blob Storage.\ndbutils.fs.ls(\"/mnt/your_azure_blob_storage_mount_point_name/\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Download source data and save it into ADLS.\ncsv_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'\nreq = requests.get(csv_url,verify=False)\nurl_content = req.content\ncsv_file = open('/dbfs/mnt/your_adls_mount_point_name/pima-indians-diabetes.data.csv', 'wb')\n\ncsv_file.write(url_content)\ncsv_file.close()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Read source data from ADLS.\ncsv_file = '/dbfs/mnt/your_adls_mount_point_name/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = pd.read_csv(csv_file, names=names)\ndataframe"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# Define data split for model training.\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\ntest_size = 0.33\nseed = 7\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Start model training.\nmodel = LogisticRegression(max_iter=200)\nmodel.fit(X_train, Y_train)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# Create folder in model artifact store as needed.\n# dbutils.fs.mkdirs(\"dbfs/mnt/your_azure_blob_storage_mount_point_name/your_model_folder_name/\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Dumping model file into model artifact store.\nfilepath = \"/dbfs/mnt/your_azure_blob_storage_mount_point_name/your_model_folder_name/\"\nfilename = \"finalized_model.pkl\"\nfilenamepath = filepath+filename\njoblib.dump(model, filenamepath)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Dumping model column header into model artifact store.\ncolumnsfilepath = \"/dbfs/mnt/your_azure_blob_storage_mount_point_name/your_model_folder_name/\"\ncolumnsfilename = \"finalized_model_column.pkl\"\ncolumnsfilenamepath = columnsfilepath+columnsfilename\nmodel_columns = list(dataframe.columns)\njoblib.dump(model_columns, columnsfilenamepath)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# List file in Azure Blob Storage.\ndbutils.fs.ls(\"/mnt/your_azure_blob_storage_mount_point_name/your_model_folder_name\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# Load saved model file and print result\nloaded_model = joblib.load(filenamepath)\nresult = loaded_model.score(X_test, Y_test)\nprint(result)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# Pick one sample for testing\npred_list = ['6','148','72','35','0','33.6','0.627','50','1']\ndf_pred_list = pd.DataFrame([pred_list], columns =['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'], dtype = float)\ndf_pred_list"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Import necessary libraries and configure access into Azure Machine Learning.\nimport mlflow\nimport mlflow.azureml\nimport azureml.mlflow\nimport azureml.core\n\nfrom azureml.core import Workspace\nfrom azureml.mlflow import get_portal_url\nfrom azureml.core.model import Model\n\nfrom azureml.core.authentication import InteractiveLoginAuthentication\ninteractive_auth = InteractiveLoginAuthentication(tenant_id=\"your_aad_tenant_id\")\n\nsubscription_id = 'your_azure_subscription_id'\n\n# Azure Machine Learning resource group NOT the managed resource group\nresource_group = 'your_resource_group_name' \n\n# Azure Machine Learning workspace name, NOT Azure Databricks workspace\nworkspace_name = 'your_aml_workspace_name'  \n\n# Instantiate Azure Machine Learning workspace\nws = Workspace.get(name=workspace_name,\n                   subscription_id=subscription_id,\n                   resource_group=resource_group,\n                  auth=interactive_auth)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Print MLFlow with AML as reference.\nuri = ws.get_mlflow_tracking_uri()\nmlflow.set_tracking_uri(uri)\nprint(uri)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# Define the experiment name for model telemetries tracking.\nexperiment_name = 'your_aml_experiment_name'\nmlflow.set_experiment(experiment_name)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["# Post model accuracy result to AML via MLFlow.\nwith mlflow.start_run():\n  # Log a metric; metrics can be updated throughout the run\n  mlflow.log_metric(\"accuracy\", result, step=1)\n  mlflow.end_run()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Packaging model file as zip for later on DevOps integration use\nimport shutil\nversion = '1'\nmodel_version = str(version)\nshutil.make_archive(model_version, 'zip', '/dbfs/mnt/your_azure_blob_storage_mount_point_name/your_model_folder_name')\nmodel_version_source = str(version) + '.zip'\nmodel_zip_path = '/dbfs/mnt/your_azure_blob_storage_mount_point_name/'\nmodel_zip_filename = 'your_model_package_name.zip'\nmodel_zip_filepath = model_zip_path+model_zip_filename\nmodel_version_dest = model_zip_filepath\nshutil.move(model_version_source, model_version_dest)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Pushing model file to AML model registry\nfilename = '/dbfs/mnt/your_azure_blob_storage_mount_point_name/your_model_package_name.zip'\nmodel_name = 'your_sklearn_model_name'\n\nmodel = Model.register(workspace = ws,\n                        model_path = filename,\n                        model_name = model_name,\n                        model_framework=Model.Framework.SCIKITLEARN,\n                        tags = {\"network\":\"none\"},\n                        description = \"your_sklearn_model_description\")"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Model API Test\nimport requests\n\nurl = \"http://your_model_api_ip:8080/predict\"\ndatas = {\"preg\":[6],\"plas\":[148],\"pres\":[72],\"skin\":[35],\"test\":[0],\"mass\":[33.6],\"pedi\":[0.627],\"age\":[50],\"class\":[0]}\nheaders = {'Content-type': 'application/json'}\nrsp = requests.post(url, json=datas, headers=headers)\nprint(rsp)\nprint(rsp.text)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Model Web Test\nimport requests\n\nurl = \"http://your_model_api_ip:8080/hello\"\nrsp = requests.get(url)\nprint(rsp)\nprint(rsp.text)"],"metadata":{},"outputs":[],"execution_count":26}],"metadata":{"name":"Model-Training","notebookId":1775183321134378},"nbformat":4,"nbformat_minor":0}
